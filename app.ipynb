{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065dce5d",
   "metadata": {},
   "source": [
    "# PLAYER PROFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e491d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PLAYERS TABLE ===\n",
      "                              player_id first_name last_name  abbr_name  \\\n",
      "0  3992e590-8f40-11ec-9f33-1965c9c46e44      Kaleb   Johnson  K.Johnson   \n",
      "\n",
      "         birth_place position  height  weight status eligibility  \n",
      "0  Hamilton, OH, USA       RB      72   225.0    NWT          JR  \n",
      "\n",
      "=== PLAYER_STATISTICS TABLE ===\n",
      "                              player_id                               team_id  \\\n",
      "0  3992e590-8f40-11ec-9f33-1965c9c46e44  a2ee495d-37c7-45ac-ac3d-d3a492a219c1   \n",
      "1  3992e590-8f40-11ec-9f33-1965c9c46e44  a2ee495d-37c7-45ac-ac3d-d3a492a219c1   \n",
      "2  3992e590-8f40-11ec-9f33-1965c9c46e44  a2ee495d-37c7-45ac-ac3d-d3a492a219c1   \n",
      "\n",
      "                              season_id  games_played  games_started  \\\n",
      "0  ff53e5e4-10ef-4842-a0b7-b489956fa07e            13              6   \n",
      "1  f58c6dbf-9dfe-487e-8b0b-af66af887206            10              5   \n",
      "2  908fbc20-f5c7-11ee-a306-c311afc28263            12             11   \n",
      "\n",
      "   rushing_yards  rushing_touchdowns  receiving_yards  receiving_touchdowns  \\\n",
      "0            779                   6               27                     0   \n",
      "1            463                   3               25                     0   \n",
      "2           1537                  21              188                     2   \n",
      "\n",
      "   kick_return_yards  fumbles  \n",
      "0              325.0        1  \n",
      "1               77.0        2  \n",
      "2                NaN        0  \n",
      "\n",
      "=== PLAYER_SEASONS TABLE ===\n",
      "                              player_id                             season_id  \\\n",
      "0  3992e590-8f40-11ec-9f33-1965c9c46e44  ff53e5e4-10ef-4842-a0b7-b489956fa07e   \n",
      "1  3992e590-8f40-11ec-9f33-1965c9c46e44  f58c6dbf-9dfe-487e-8b0b-af66af887206   \n",
      "2  3992e590-8f40-11ec-9f33-1965c9c46e44  908fbc20-f5c7-11ee-a306-c311afc28263   \n",
      "\n",
      "   season_year season_type  \n",
      "0         2022         REG  \n",
      "1         2023         REG  \n",
      "2         2024         REG  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_17736\\1782108679.py:109: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# -----------------------------\n",
    "# Load JSON\n",
    "# -----------------------------\n",
    "with open(\"player_profile.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    player = json.load(f)\n",
    "\n",
    "# ======================================================\n",
    "# 1) PLAYERS TABLE\n",
    "# ======================================================\n",
    "df_players = pd.DataFrame([{\n",
    "    \"player_id\": player.get(\"id\"),\n",
    "    \"first_name\": player.get(\"first_name\"),\n",
    "    \"last_name\": player.get(\"last_name\"),\n",
    "    \"abbr_name\": player.get(\"abbr_name\"),\n",
    "    \"birth_place\": player.get(\"birth_place\"),\n",
    "    \"position\": player.get(\"position\"),\n",
    "    \"height\": player.get(\"height\"),\n",
    "    \"weight\": player.get(\"weight\"),\n",
    "    \"status\": player.get(\"status\"),\n",
    "    \"eligibility\": player.get(\"eligibility\")\n",
    "}])\n",
    "\n",
    "# ======================================================\n",
    "# 2) PLAYER STATISTICS TABLE\n",
    "# ======================================================\n",
    "\n",
    "rows_stats = []\n",
    "\n",
    "for season in player.get(\"seasons\", []):\n",
    "    season_id = season.get(\"id\")\n",
    "\n",
    "    for team in season.get(\"teams\", []):\n",
    "        stats = team.get(\"statistics\", {})\n",
    "\n",
    "        rows_stats.append({\n",
    "            \"player_id\": player.get(\"id\"),\n",
    "            \"team_id\": team.get(\"id\"),\n",
    "            \"season_id\": season_id,\n",
    "\n",
    "            # Basic\n",
    "            \"games_played\": stats.get(\"games_played\"),\n",
    "            \"games_started\": stats.get(\"games_started\"),\n",
    "\n",
    "            # Rushing\n",
    "            \"rushing_yards\": stats.get(\"rushing\", {}).get(\"yards\"),\n",
    "            \"rushing_touchdowns\": stats.get(\"rushing\", {}).get(\"touchdowns\"),\n",
    "\n",
    "            # Receiving\n",
    "            \"receiving_yards\": stats.get(\"receiving\", {}).get(\"yards\"),\n",
    "            \"receiving_touchdowns\": stats.get(\"receiving\", {}).get(\"touchdowns\"),\n",
    "\n",
    "            # Kick Return\n",
    "            \"kick_return_yards\": stats.get(\"kick_returns\", {}).get(\"yards\"),\n",
    "\n",
    "            # Fumbles\n",
    "            \"fumbles\": stats.get(\"fumbles\", {}).get(\"fumbles\"),\n",
    "        })\n",
    "\n",
    "df_player_statistics = pd.DataFrame(rows_stats)\n",
    "\n",
    "# ======================================================\n",
    "# 3) PLAYER SEASONS TABLE\n",
    "# ======================================================\n",
    "\n",
    "rows_seasons = []\n",
    "\n",
    "for season in player.get(\"seasons\", []):\n",
    "    rows_seasons.append({\n",
    "        \"player_id\": player.get(\"id\"),\n",
    "        \"season_id\": season.get(\"id\"),\n",
    "        \"season_year\": season.get(\"year\"),\n",
    "        \"season_type\": season.get(\"type\"),\n",
    "    })\n",
    "\n",
    "df_player_seasons = pd.DataFrame(rows_seasons)\n",
    "\n",
    "# ------------------------------------------\n",
    "# SHOW THE RESULT\n",
    "# ------------------------------------------\n",
    "print(\"\\n=== PLAYERS TABLE ===\")\n",
    "print(df_players)\n",
    "\n",
    "print(\"\\n=== PLAYER_STATISTICS TABLE ===\")\n",
    "print(df_player_statistics)\n",
    "\n",
    "print(\"\\n=== PLAYER_SEASONS TABLE ===\")\n",
    "print(df_player_seasons)\n",
    "\n",
    "\n",
    "def clean_df(df):\n",
    "    df = df.astype(\"object\")  # convert all to object\n",
    "    def clean_value(x):\n",
    "        if x is None: return None\n",
    "        if pd.isna(x): return None\n",
    "        if str(x).strip().lower() in [\"nan\", \"none\", \"null\", \"nat\"]:\n",
    "            return None\n",
    "        return x\n",
    "    return df.apply(lambda col: col.map(clean_value))\n",
    "\n",
    "df_players = clean_df(df_players)\n",
    "df_player_statistics = clean_df(df_player_statistics)\n",
    "df_player_seasons = clean_df(df_player_seasons)\n",
    "\n",
    "\n",
    "def fix_nan_strings(df):\n",
    "    return df.applymap(\n",
    "        lambda x: None \n",
    "        if (x is None or pd.isna(x) or str(x).strip().lower() in [\"nan\", \"none\", \"null\", \"nat\", \"\"]) \n",
    "        else x\n",
    "    )\n",
    "\n",
    "df_player_statistics = fix_nan_strings(df_player_statistics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e05f46",
   "metadata": {},
   "source": [
    "# RANKINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f4faf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load JSON file into a variable\n",
    "with open(\"ranking.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    rankingdata = json.load(f)\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for team in rankingdata.get(\"rankings\", []):\n",
    "    rows.append({\n",
    "        \"poll_id\": rankingdata[\"poll\"].get(\"id\"),\n",
    "        \"poll_name\": rankingdata[\"poll\"].get(\"name\"),\n",
    "        \"poll_alias\": rankingdata[\"poll\"].get(\"alias\"),\n",
    "        \"season\": rankingdata.get(\"season\"),\n",
    "        \"week\": rankingdata.get(\"week\"),\n",
    "        \"effective_time\": rankingdata.get(\"effective_time\"),\n",
    "\n",
    "        \"team_id\": team.get(\"id\"),\n",
    "        \"team_name\": team.get(\"name\"),\n",
    "        \"team_market\": team.get(\"market\"),\n",
    "        \"rank\": team.get(\"rank\"),\n",
    "        \"points\": team.get(\"points\"),\n",
    "        \"first_place_votes\": team.get(\"fp_votes\")\n",
    "    })\n",
    "\n",
    "\n",
    "df_rankings = pd.DataFrame(rows)\n",
    "\n",
    "# df_rankings.info()\n",
    "\n",
    "# df_rankings\n",
    "\n",
    "candidate_rows = []\n",
    "\n",
    "for c in rankingdata.get(\"candidates\", []):\n",
    "    candidate_rows.append({\n",
    "        # \"poll_id\": rankingdata[\"poll\"].get(\"id\"),\n",
    "        # \"poll_name\": rankingdata[\"poll\"].get(\"name\"),\n",
    "        # \"poll_alias\": rankingdata[\"poll\"].get(\"alias\"),\n",
    "        # \"season\": rankingdata.get(\"season\"),\n",
    "        # \"week\": rankingdata.get(\"week\"),\n",
    "        # \"effective_time\": rankingdata.get(\"effective_time\"),\n",
    "\n",
    "        \"team_id\": c.get(\"id\"),\n",
    "        \"team_name\": c.get(\"name\"),\n",
    "        \"team_market\": c.get(\"market\"),\n",
    "        \"votes\": c.get(\"votes\")\n",
    "    })\n",
    "\n",
    "df_candidates = pd.DataFrame(candidate_rows)\n",
    "# df_candidates\n",
    "\n",
    "# df_candidates.info()\n",
    "# df_rankings.info()\n",
    "\n",
    "# df_candidates.to_csv(\"candidates.csv\", index=False, encoding=\"utf-8\")\n",
    "# df_rankings.to_csv(\"rankings.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# df_rankings\n",
    "# # df_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b93256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype              \n",
      "---  ------             --------------  -----              \n",
      " 0   poll_id            25 non-null     object             \n",
      " 1   poll_name          25 non-null     object             \n",
      " 2   poll_alias         25 non-null     object             \n",
      " 3   season             25 non-null     int64              \n",
      " 4   week               25 non-null     int64              \n",
      " 5   effective_time     25 non-null     datetime64[ns, UTC]\n",
      " 6   team_id            25 non-null     object             \n",
      " 7   team_name          25 non-null     object             \n",
      " 8   team_market        25 non-null     object             \n",
      " 9   rank               25 non-null     int64              \n",
      " 10  points             25 non-null     int64              \n",
      " 11  first_place_votes  25 non-null     int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(5), object(6)\n",
      "memory usage: 2.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   team_id      24 non-null     object\n",
      " 1   team_name    24 non-null     object\n",
      " 2   team_market  24 non-null     object\n",
      " 3   votes        24 non-null     int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 900.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_rankings[\"effective_time\"] = pd.to_datetime(df_rankings[\"effective_time\"])\n",
    "\n",
    "df_candidates.to_csv(\"candidates.csv\", index=False, encoding=\"utf-8\")\n",
    "df_rankings.to_csv(\"rankings.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "df_rankings.info()\n",
    "df_candidates.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a764e7",
   "metadata": {},
   "source": [
    "# ROSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c60f3c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load JSON file into a variable\n",
    "with open(\"roster.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    rosterdata = json.load(f)\n",
    "\n",
    "# # Now you can use roster_data like a normal Python dict\n",
    "# print(rosterdata)\n",
    "#rosterdata \n",
    "\n",
    "# Team - [id, name, market,alias,founded,mascot,fight_song,championships_won,conference_titles,playoff_appearances]\n",
    "# franchise = [id,name]\n",
    "# venue = [id,name,city,state,country,zip,address,capacity,surface,roof_type,sr_id]\n",
    "# location = [lat, lng]\n",
    "# division = [id,name,alias]\n",
    "# conference = [id,name,alias]\n",
    "# coaches = [id,full_name,first_name,last_name,position ]\n",
    "# players = [id,name,jersey,last_name,first_name,abbr_name,weight,height,position,birth_place,status,eligibility]\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for player in rosterdata.get(\"players\", []):\n",
    "    \n",
    "    # Safe coach extraction (coaches is a LIST)\n",
    "    coach = rosterdata.get(\"coaches\", [{}])[0]\n",
    "\n",
    "    rows.append({\n",
    "\n",
    "        # TEAM\n",
    "        \"team_id\": rosterdata.get(\"id\"),\n",
    "        \"name\": rosterdata.get(\"name\"),\n",
    "        \"market\": rosterdata.get(\"market\"),\n",
    "        \"alias\": rosterdata.get(\"alias\"),\n",
    "        \"founded\": rosterdata.get(\"founded\"),\n",
    "        \"mascot\": rosterdata.get(\"mascot\"),\n",
    "        \"fight_song\": rosterdata.get(\"fight_song\"),\n",
    "        \"championships_won\": rosterdata.get(\"championships_won\"),\n",
    "        \"conference_titles\": rosterdata.get(\"conference_titles\"),\n",
    "        \"playoff_appearances\": rosterdata.get(\"playoff_appearances\"),\n",
    "\n",
    "        # FRANCHISE\n",
    "        \"franchise_id\": rosterdata[\"franchise\"].get(\"id\"),\n",
    "        \"franchise_name\": rosterdata[\"franchise\"].get(\"name\"),\n",
    "\n",
    "        # VENUE\n",
    "        \"venue_id\": rosterdata[\"venue\"].get(\"id\"),\n",
    "        \"venue_name\": rosterdata[\"venue\"].get(\"name\"),\n",
    "        \"venue_city\": rosterdata[\"venue\"].get(\"city\"),\n",
    "        \"venue_state\": rosterdata[\"venue\"].get(\"state\"),\n",
    "        \"venue_country\": rosterdata[\"venue\"].get(\"country\"),\n",
    "        \"venue_zip\": rosterdata[\"venue\"].get(\"zip\"),\n",
    "        \"venue_address\": rosterdata[\"venue\"].get(\"address\"),\n",
    "        \"venue_capacity\": rosterdata[\"venue\"].get(\"capacity\"),\n",
    "        \"venue_surface\": rosterdata[\"venue\"].get(\"surface\"),\n",
    "        \"venue_roof_type\": rosterdata[\"venue\"].get(\"roof_type\"),\n",
    "        \"venue_sr_id\": rosterdata[\"venue\"].get(\"sr_id\"),\n",
    "\n",
    "        # LOCATION (inside venue)\n",
    "        \"location_lat\": rosterdata[\"venue\"][\"location\"].get(\"lat\"),\n",
    "        \"location_lng\": rosterdata[\"venue\"][\"location\"].get(\"lng\"),\n",
    "\n",
    "        # DIVISION\n",
    "        \"division_id\": rosterdata[\"division\"].get(\"id\"),\n",
    "        \"division_name\": rosterdata[\"division\"].get(\"name\"),\n",
    "        \"division_alias\": rosterdata[\"division\"].get(\"alias\"),\n",
    "\n",
    "        # CONFERENCE\n",
    "        \"conference_id\": rosterdata[\"conference\"].get(\"id\"),\n",
    "        \"conference_name\": rosterdata[\"conference\"].get(\"name\"),\n",
    "        \"conference_alias\": rosterdata[\"conference\"].get(\"alias\"),\n",
    "\n",
    "        # COACH (first coach only)\n",
    "        \"coach_id\": coach.get(\"id\"),\n",
    "        \"coach_full_name\": coach.get(\"full_name\"),\n",
    "        \"coach_first_name\": coach.get(\"first_name\"),\n",
    "        \"coach_last_name\": coach.get(\"last_name\"),\n",
    "        \"coach_position\": coach.get(\"position\"),\n",
    "\n",
    "        # PLAYER\n",
    "        \"player_id\": player.get(\"id\"),\n",
    "        \"player_name\": player.get(\"name\"),\n",
    "        \"player_jersey\": player.get(\"jersey\"),\n",
    "        \"player_first_name\": player.get(\"first_name\"),\n",
    "        \"player_last_name\": player.get(\"last_name\"),\n",
    "        \"player_abbr_name\": player.get(\"abbr_name\"),\n",
    "        \"player_weight\": player.get(\"weight\"),\n",
    "        \"player_height\": player.get(\"height\"),\n",
    "        \"player_position\": player.get(\"position\"),\n",
    "        \"player_birth_place\": player.get(\"birth_place\"),\n",
    "        \"player_status\": player.get(\"status\"),\n",
    "        \"player_eligibility\": player.get(\"eligibility\"),\n",
    "        \"player_name_suffix\": player.get(\"name_suffix\")\n",
    "    })\n",
    "\n",
    "df_roster = pd.DataFrame(rows)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# df_roster.to_csv(\"roster.csv\", index=False, encoding=\"utf-8\")\n",
    "# df_roster.info()\n",
    "# df_roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "354ca57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125 entries, 0 to 124\n",
      "Data columns (total 49 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   team_id              125 non-null    object \n",
      " 1   name                 125 non-null    object \n",
      " 2   market               125 non-null    object \n",
      " 3   alias                125 non-null    object \n",
      " 4   founded              125 non-null    int64  \n",
      " 5   mascot               125 non-null    object \n",
      " 6   fight_song           125 non-null    object \n",
      " 7   championships_won    125 non-null    int64  \n",
      " 8   conference_titles    125 non-null    int64  \n",
      " 9   playoff_appearances  125 non-null    int64  \n",
      " 10  franchise_id         125 non-null    object \n",
      " 11  franchise_name       125 non-null    object \n",
      " 12  venue_id             125 non-null    object \n",
      " 13  venue_name           125 non-null    object \n",
      " 14  venue_city           125 non-null    object \n",
      " 15  venue_state          125 non-null    object \n",
      " 16  venue_country        125 non-null    object \n",
      " 17  venue_zip            125 non-null    object \n",
      " 18  venue_address        125 non-null    object \n",
      " 19  venue_capacity       125 non-null    int64  \n",
      " 20  venue_surface        125 non-null    object \n",
      " 21  venue_roof_type      125 non-null    object \n",
      " 22  venue_sr_id          125 non-null    object \n",
      " 23  location_lat         125 non-null    float64\n",
      " 24  location_lng         125 non-null    float64\n",
      " 25  division_id          125 non-null    object \n",
      " 26  division_name        125 non-null    object \n",
      " 27  division_alias       125 non-null    object \n",
      " 28  conference_id        125 non-null    object \n",
      " 29  conference_name      125 non-null    object \n",
      " 30  conference_alias     125 non-null    object \n",
      " 31  coach_id             125 non-null    object \n",
      " 32  coach_full_name      125 non-null    object \n",
      " 33  coach_first_name     125 non-null    object \n",
      " 34  coach_last_name      125 non-null    object \n",
      " 35  coach_position       125 non-null    object \n",
      " 36  player_id            125 non-null    object \n",
      " 37  player_name          125 non-null    object \n",
      " 38  player_jersey        125 non-null    Int64  \n",
      " 39  player_first_name    125 non-null    object \n",
      " 40  player_last_name     125 non-null    object \n",
      " 41  player_abbr_name     125 non-null    object \n",
      " 42  player_weight        125 non-null    Int64  \n",
      " 43  player_height        125 non-null    Int64  \n",
      " 44  player_position      125 non-null    object \n",
      " 45  player_birth_place   125 non-null    object \n",
      " 46  player_status        125 non-null    object \n",
      " 47  player_eligibility   125 non-null    object \n",
      " 48  player_name_suffix   12 non-null     object \n",
      "dtypes: Int64(3), float64(2), int64(5), object(39)\n",
      "memory usage: 48.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_roster[\"location_lat\"] = pd.to_numeric(df_roster[\"location_lat\"], errors=\"coerce\")\n",
    "df_roster[\"location_lng\"] = pd.to_numeric(df_roster[\"location_lng\"], errors=\"coerce\")\n",
    "\n",
    "df_roster[\"player_height\"] = pd.to_numeric(df_roster[\"player_height\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df_roster[\"player_weight\"] = pd.to_numeric(df_roster[\"player_weight\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "df_roster[\"player_jersey\"] = pd.to_numeric(df_roster[\"player_jersey\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "df_roster.to_csv(\"roster.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "df_roster.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62225de4",
   "metadata": {},
   "source": [
    "# SEASON SCHEDULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "835b11b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_id</th>\n",
       "      <th>season_year</th>\n",
       "      <th>season_type</th>\n",
       "      <th>season_name</th>\n",
       "      <th>week_id</th>\n",
       "      <th>week_sequence</th>\n",
       "      <th>week_title</th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_status</th>\n",
       "      <th>scheduled</th>\n",
       "      <th>...</th>\n",
       "      <th>tz_home</th>\n",
       "      <th>tz_away</th>\n",
       "      <th>weather_condition</th>\n",
       "      <th>weather_humidity</th>\n",
       "      <th>weather_temp</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>home_points_total</th>\n",
       "      <th>away_points_total</th>\n",
       "      <th>period_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>754e4990-efc7-11ef-bb2a-5d2d22b9215e</td>\n",
       "      <td>2025</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>c6cd2df1-2ab8-4b0d-992b-1cfacdd81dfd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ff0532c8-cc0d-473a-b47f-421eccf4d427</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-08-23T16:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>US/Central</td>\n",
       "      <td>US/Central</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>88.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>754e4990-efc7-11ef-bb2a-5d2d22b9215e</td>\n",
       "      <td>2025</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>c6cd2df1-2ab8-4b0d-992b-1cfacdd81dfd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7770d00f-8df8-4629-935e-d22b8592a6b5</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-08-23T17:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>US/Central</td>\n",
       "      <td>US/Central</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>84.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>754e4990-efc7-11ef-bb2a-5d2d22b9215e</td>\n",
       "      <td>2025</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>c6cd2df1-2ab8-4b0d-992b-1cfacdd81dfd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31adc52f-a271-4e44-a252-7f6093d08be6</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-08-23T20:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>US/Pacific</td>\n",
       "      <td>US/Mountain</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>17.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E</td>\n",
       "      <td>38.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>754e4990-efc7-11ef-bb2a-5d2d22b9215e</td>\n",
       "      <td>2025</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>c6cd2df1-2ab8-4b0d-992b-1cfacdd81dfd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>e82376a4-dbbf-4d70-afb0-fbd6a54553f4</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-08-23T20:30:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>US/Pacific</td>\n",
       "      <td>US/Central</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>754e4990-efc7-11ef-bb2a-5d2d22b9215e</td>\n",
       "      <td>2025</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>c6cd2df1-2ab8-4b0d-992b-1cfacdd81dfd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dfcb530d-3329-4624-8428-c71eea57c449</td>\n",
       "      <td>closed</td>\n",
       "      <td>2025-08-23T22:30:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>US/Central</td>\n",
       "      <td>US/Pacific</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>754e4990-efc7-11ef-bb2a-5d2d22b9215e</td>\n",
       "      <td>2025</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>8d2f27f4-2316-469e-9698-01df7ca90292</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>c26a2823-93de-4dc9-8cfb-e92be1eb7876</td>\n",
       "      <td>scheduled</td>\n",
       "      <td>2026-01-03T01:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>754e4990-efc7-11ef-bb2a-5d2d22b9215e</td>\n",
       "      <td>2025</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>8d2f27f4-2316-469e-9698-01df7ca90292</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>17c5bcbb-4bbe-40b2-8af5-03508a991a62</td>\n",
       "      <td>time-tbd</td>\n",
       "      <td>2026-01-05T18:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>754e4990-efc7-11ef-bb2a-5d2d22b9215e</td>\n",
       "      <td>2025</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>6b37eac4-9952-4e73-a4f6-31b3bc3a0087</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>9d6f8e94-73bd-4765-bc52-01f6008adfba</td>\n",
       "      <td>scheduled</td>\n",
       "      <td>2026-01-09T00:30:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>754e4990-efc7-11ef-bb2a-5d2d22b9215e</td>\n",
       "      <td>2025</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>6b37eac4-9952-4e73-a4f6-31b3bc3a0087</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>37dbbaa6-4612-43bc-b924-529496160bd8</td>\n",
       "      <td>scheduled</td>\n",
       "      <td>2026-01-10T00:30:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>754e4990-efc7-11ef-bb2a-5d2d22b9215e</td>\n",
       "      <td>2025</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>a4bdd09d-77db-4262-bc1a-2a87e4987557</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>ac60aab5-2638-45de-87f0-037e3f199282</td>\n",
       "      <td>scheduled</td>\n",
       "      <td>2026-01-20T00:30:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1688 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 season_id  season_year season_type  \\\n",
       "0     754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
       "1     754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
       "2     754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
       "3     754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
       "4     754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
       "...                                    ...          ...         ...   \n",
       "1683  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
       "1684  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
       "1685  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
       "1686  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
       "1687  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
       "\n",
       "     season_name                               week_id  week_sequence  \\\n",
       "0            REG  c6cd2df1-2ab8-4b0d-992b-1cfacdd81dfd              1   \n",
       "1            REG  c6cd2df1-2ab8-4b0d-992b-1cfacdd81dfd              1   \n",
       "2            REG  c6cd2df1-2ab8-4b0d-992b-1cfacdd81dfd              1   \n",
       "3            REG  c6cd2df1-2ab8-4b0d-992b-1cfacdd81dfd              1   \n",
       "4            REG  c6cd2df1-2ab8-4b0d-992b-1cfacdd81dfd              1   \n",
       "...          ...                                   ...            ...   \n",
       "1683         REG  8d2f27f4-2316-469e-9698-01df7ca90292             19   \n",
       "1684         REG  8d2f27f4-2316-469e-9698-01df7ca90292             19   \n",
       "1685         REG  6b37eac4-9952-4e73-a4f6-31b3bc3a0087             20   \n",
       "1686         REG  6b37eac4-9952-4e73-a4f6-31b3bc3a0087             20   \n",
       "1687         REG  a4bdd09d-77db-4262-bc1a-2a87e4987557             21   \n",
       "\n",
       "     week_title                               game_id game_status  \\\n",
       "0             1  ff0532c8-cc0d-473a-b47f-421eccf4d427      closed   \n",
       "1             1  7770d00f-8df8-4629-935e-d22b8592a6b5      closed   \n",
       "2             1  31adc52f-a271-4e44-a252-7f6093d08be6      closed   \n",
       "3             1  e82376a4-dbbf-4d70-afb0-fbd6a54553f4      closed   \n",
       "4             1  dfcb530d-3329-4624-8428-c71eea57c449      closed   \n",
       "...         ...                                   ...         ...   \n",
       "1683         19  c26a2823-93de-4dc9-8cfb-e92be1eb7876   scheduled   \n",
       "1684         19  17c5bcbb-4bbe-40b2-8af5-03508a991a62    time-tbd   \n",
       "1685         20  9d6f8e94-73bd-4765-bc52-01f6008adfba   scheduled   \n",
       "1686         20  37dbbaa6-4612-43bc-b924-529496160bd8   scheduled   \n",
       "1687         21  ac60aab5-2638-45de-87f0-037e3f199282   scheduled   \n",
       "\n",
       "                      scheduled  ...     tz_home      tz_away  \\\n",
       "0     2025-08-23T16:00:00+00:00  ...  US/Central   US/Central   \n",
       "1     2025-08-23T17:00:00+00:00  ...  US/Central   US/Central   \n",
       "2     2025-08-23T20:00:00+00:00  ...  US/Pacific  US/Mountain   \n",
       "3     2025-08-23T20:30:00+00:00  ...  US/Pacific   US/Central   \n",
       "4     2025-08-23T22:30:00+00:00  ...  US/Central   US/Pacific   \n",
       "...                         ...  ...         ...          ...   \n",
       "1683  2026-01-03T01:00:00+00:00  ...        None         None   \n",
       "1684  2026-01-05T18:00:00+00:00  ...        None         None   \n",
       "1685  2026-01-09T00:30:00+00:00  ...        None         None   \n",
       "1686  2026-01-10T00:30:00+00:00  ...        None         None   \n",
       "1687  2026-01-20T00:30:00+00:00  ...        None         None   \n",
       "\n",
       "     weather_condition weather_humidity weather_temp wind_speed  \\\n",
       "0        Partly cloudy             88.0         67.0        2.0   \n",
       "1             Overcast             84.0         80.0        2.0   \n",
       "2                Sunny             17.0        103.0        5.0   \n",
       "3                Sunny             18.0         98.0        5.0   \n",
       "4                Sunny             50.0         85.0       12.0   \n",
       "...                ...              ...          ...        ...   \n",
       "1683              None              NaN          NaN        NaN   \n",
       "1684              None              NaN          NaN        NaN   \n",
       "1685              None              NaN          NaN        NaN   \n",
       "1686              None              NaN          NaN        NaN   \n",
       "1687              None              NaN          NaN        NaN   \n",
       "\n",
       "      wind_direction home_points_total  away_points_total period_count  \n",
       "0                ESE              21.0               24.0            4  \n",
       "1                SSE              20.0                6.0            4  \n",
       "2                  E              38.0               31.0            4  \n",
       "3                NNE               0.0               42.0            4  \n",
       "4                NNE              31.0                7.0            4  \n",
       "...              ...               ...                ...          ...  \n",
       "1683            None               NaN                NaN            0  \n",
       "1684            None               NaN                NaN            0  \n",
       "1685            None               NaN                NaN            0  \n",
       "1686            None               NaN                NaN            0  \n",
       "1687            None               NaN                NaN            0  \n",
       "\n",
       "[1688 rows x 52 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load JSON file into a variable\n",
    "with open(\"sched.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sea_schedule = json.load(f)\n",
    "     \n",
    "\n",
    "data = sea_schedule   \n",
    "\n",
    "rows = []\n",
    "\n",
    "season = data\n",
    "\n",
    "for week in season.get(\"weeks\", []):\n",
    "    for game in week.get(\"games\", []):\n",
    "\n",
    "        # shortcut references\n",
    "        venue = game.get(\"venue\", {})\n",
    "        home = game.get(\"home\", {})\n",
    "        away = game.get(\"away\", {})\n",
    "        broadcast = game.get(\"broadcast\", {})\n",
    "        timezones = game.get(\"time_zones\", {})\n",
    "        weather = game.get(\"weather\", {})\n",
    "        wind = weather.get(\"wind\", {})\n",
    "        scoring = game.get(\"scoring\", {})\n",
    "\n",
    "        row = {\n",
    "            # ------------------------\n",
    "            # SEASON INFO\n",
    "            # ------------------------\n",
    "            \"season_id\": season.get(\"id\"),\n",
    "            \"season_year\": season.get(\"year\"),\n",
    "            \"season_type\": season.get(\"type\"),\n",
    "            \"season_name\": season.get(\"name\"),\n",
    "\n",
    "            # ------------------------\n",
    "            # WEEK INFO\n",
    "            # ------------------------\n",
    "            \"week_id\": week.get(\"id\"),\n",
    "            \"week_sequence\": week.get(\"sequence\"),\n",
    "            \"week_title\": week.get(\"title\"),\n",
    "\n",
    "            # ------------------------\n",
    "            # GAME INFO\n",
    "            # ------------------------\n",
    "            \"game_id\": game.get(\"id\"),\n",
    "            \"game_status\": game.get(\"status\"),\n",
    "            \"scheduled\": game.get(\"scheduled\"),\n",
    "            \"attendance\": game.get(\"attendance\"),\n",
    "            \"entry_mode\": game.get(\"entry_mode\"),\n",
    "            \"coverage\": game.get(\"coverage\"),\n",
    "            \"sr_id\": game.get(\"sr_id\"),\n",
    "            \"neutral_site\": game.get(\"neutral_site\"),\n",
    "            \"game_type\": game.get(\"game_type\"),\n",
    "            \"conference_game\": game.get(\"conference_game\"),\n",
    "            \"duration\": game.get(\"duration\"),\n",
    "            \"expected_latency\": game.get(\"expected_latency\"),\n",
    "\n",
    "            # ------------------------\n",
    "            # VENUE INFO\n",
    "            # ------------------------\n",
    "            \"venue_id\": venue.get(\"id\"),\n",
    "            \"venue_name\": venue.get(\"name\"),\n",
    "            \"venue_city\": venue.get(\"city\"),\n",
    "            \"venue_state\": venue.get(\"state\"),\n",
    "            \"venue_country\": venue.get(\"country\"),\n",
    "            \"venue_zip\": venue.get(\"zip\"),\n",
    "            \"venue_address\": venue.get(\"address\"),\n",
    "            \"venue_capacity\": venue.get(\"capacity\"),\n",
    "            \"venue_surface\": venue.get(\"surface\"),\n",
    "            \"venue_roof\": venue.get(\"roof_type\"),\n",
    "            \"venue_lat\": venue.get(\"location\", {}).get(\"lat\"),\n",
    "            \"venue_lng\": venue.get(\"location\", {}).get(\"lng\"),\n",
    "\n",
    "            # ------------------------\n",
    "            # TEAMS (HOME)\n",
    "            # ------------------------\n",
    "            \"home_id\": home.get(\"id\"),\n",
    "            \"home_name\": home.get(\"name\"),\n",
    "            \"home_alias\": home.get(\"alias\"),\n",
    "            \"home_game_number\": home.get(\"game_number\"),\n",
    "\n",
    "            # ------------------------\n",
    "            # TEAMS (AWAY)\n",
    "            # ------------------------\n",
    "            \"away_id\": away.get(\"id\"),\n",
    "            \"away_name\": away.get(\"name\"),\n",
    "            \"away_alias\": away.get(\"alias\"),\n",
    "            \"away_game_number\": away.get(\"game_number\"),\n",
    "\n",
    "            # ------------------------\n",
    "            # BROADCAST\n",
    "            # ------------------------\n",
    "            \"broadcast_network\": broadcast.get(\"network\"),\n",
    "            \"broadcast_satellite\": broadcast.get(\"satellite\"),\n",
    "\n",
    "            # ------------------------\n",
    "            # TIME ZONES\n",
    "            # ------------------------\n",
    "            \"tz_venue\": timezones.get(\"venue\"),\n",
    "            \"tz_home\": timezones.get(\"home\"),\n",
    "            \"tz_away\": timezones.get(\"away\"),\n",
    "\n",
    "            # ------------------------\n",
    "            # WEATHER\n",
    "            # ------------------------\n",
    "            \"weather_condition\": weather.get(\"condition\"),\n",
    "            \"weather_humidity\": weather.get(\"humidity\"),\n",
    "            \"weather_temp\": weather.get(\"temp\"),\n",
    "            \"wind_speed\": wind.get(\"speed\"),\n",
    "            \"wind_direction\": wind.get(\"direction\"),\n",
    "\n",
    "            # ------------------------\n",
    "            # SCORING (1st-level)\n",
    "            # ------------------------\n",
    "            \"home_points_total\": scoring.get(\"home_points\"),\n",
    "            \"away_points_total\": scoring.get(\"away_points\"),\n",
    "\n",
    "            # ------------------------\n",
    "            # SCORING PERIODS (just count)\n",
    "            # ------------------------\n",
    "            \"period_count\": len(scoring.get(\"periods\", [])),\n",
    "        }\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "df_schedule = pd.DataFrame(rows)\n",
    "\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# df_schedule.to_csv(\"schedule.csv\", index=False, encoding=\"utf-8\")\n",
    "# df_schedule.info()\n",
    "df_schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650bc0a",
   "metadata": {},
   "source": [
    "home_id              1680 non-null   object             \n",
    " 32  home_name            1688 non-null   object             \n",
    " 33  home_alias           1688 non-null   object             \n",
    " 34  home_game_number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c4922777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1688 entries, 0 to 1687\n",
      "Data columns (total 52 columns):\n",
      " #   Column               Non-Null Count  Dtype              \n",
      "---  ------               --------------  -----              \n",
      " 0   season_id            1688 non-null   object             \n",
      " 1   season_year          1688 non-null   int64              \n",
      " 2   season_type          1688 non-null   object             \n",
      " 3   season_name          1688 non-null   object             \n",
      " 4   week_id              1688 non-null   object             \n",
      " 5   week_sequence        1688 non-null   int64              \n",
      " 6   week_title           1688 non-null   object             \n",
      " 7   game_id              1688 non-null   object             \n",
      " 8   game_status          1688 non-null   object             \n",
      " 9   scheduled            1688 non-null   datetime64[ns, UTC]\n",
      " 10  attendance           1402 non-null   float64            \n",
      " 11  entry_mode           1688 non-null   object             \n",
      " 12  coverage             1688 non-null   object             \n",
      " 13  sr_id                1609 non-null   object             \n",
      " 14  neutral_site         77 non-null     object             \n",
      " 15  game_type            1688 non-null   object             \n",
      " 16  conference_game      1688 non-null   bool               \n",
      " 17  duration             1407 non-null   object             \n",
      " 18  expected_latency     812 non-null    float64            \n",
      " 19  venue_id             1657 non-null   object             \n",
      " 20  venue_name           1657 non-null   object             \n",
      " 21  venue_city           1657 non-null   object             \n",
      " 22  venue_state          1656 non-null   object             \n",
      " 23  venue_country        1657 non-null   object             \n",
      " 24  venue_zip            1656 non-null   object             \n",
      " 25  venue_address        1657 non-null   object             \n",
      " 26  venue_capacity       1657 non-null   float64            \n",
      " 27  venue_surface        1657 non-null   object             \n",
      " 28  venue_roof           1657 non-null   object             \n",
      " 29  venue_lat            1657 non-null   float64            \n",
      " 30  venue_lng            1657 non-null   float64            \n",
      " 31  home_id              1680 non-null   object             \n",
      " 32  home_name            1688 non-null   object             \n",
      " 33  home_alias           1688 non-null   object             \n",
      " 34  home_game_number     1608 non-null   float64            \n",
      " 35  away_id              1672 non-null   object             \n",
      " 36  away_name            1688 non-null   object             \n",
      " 37  away_alias           1688 non-null   object             \n",
      " 38  away_game_number     1608 non-null   float64            \n",
      " 39  broadcast_network    1673 non-null   object             \n",
      " 40  broadcast_satellite  502 non-null    object             \n",
      " 41  tz_venue             1657 non-null   object             \n",
      " 42  tz_home              1609 non-null   object             \n",
      " 43  tz_away              1554 non-null   object             \n",
      " 44  weather_condition    1416 non-null   object             \n",
      " 45  weather_humidity     1416 non-null   float64            \n",
      " 46  weather_temp         1416 non-null   float64            \n",
      " 47  wind_speed           1416 non-null   float64            \n",
      " 48  wind_direction       1416 non-null   object             \n",
      " 49  home_points_total    1413 non-null   float64            \n",
      " 50  away_points_total    1413 non-null   float64            \n",
      " 51  period_count         1688 non-null   int64              \n",
      "dtypes: bool(1), datetime64[ns, UTC](1), float64(12), int64(3), object(35)\n",
      "memory usage: 674.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_id</th>\n",
       "      <th>home_name</th>\n",
       "      <th>home_game_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0dd26ea7-79fb-4ea8-bf48-7c31108e14a3</td>\n",
       "      <td>Kansas State Wildcats</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deea4446-2bee-4144-96bc-9f1e8ccceee8</td>\n",
       "      <td>Nicholls State Colonels</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5f105ef1-4d01-45a5-bfbb-497ee86a8eba</td>\n",
       "      <td>UNLV Rebels</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e3f5ade-a73e-44d5-a042-0a32f291d6f4</td>\n",
       "      <td>Portland State Vikings</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d0212bdb-5dd4-4604-a221-9adf26e6fd4a</td>\n",
       "      <td>Kansas Jayhawks</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>e7ce7680-f058-11ee-89df-6558e107cb95</td>\n",
       "      <td>Team TBD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>None</td>\n",
       "      <td>FCS Semifinal 1 (win)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>e7ce7680-f058-11ee-89df-6558e107cb95</td>\n",
       "      <td>Team TBD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>e7ce7680-f058-11ee-89df-6558e107cb95</td>\n",
       "      <td>Team TBD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>None</td>\n",
       "      <td>Peach Bowl (win)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1688 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   home_id                home_name  \\\n",
       "0     0dd26ea7-79fb-4ea8-bf48-7c31108e14a3    Kansas State Wildcats   \n",
       "1     deea4446-2bee-4144-96bc-9f1e8ccceee8  Nicholls State Colonels   \n",
       "2     5f105ef1-4d01-45a5-bfbb-497ee86a8eba              UNLV Rebels   \n",
       "3     1e3f5ade-a73e-44d5-a042-0a32f291d6f4   Portland State Vikings   \n",
       "4     d0212bdb-5dd4-4604-a221-9adf26e6fd4a          Kansas Jayhawks   \n",
       "...                                    ...                      ...   \n",
       "1683  e7ce7680-f058-11ee-89df-6558e107cb95                 Team TBD   \n",
       "1684                                  None    FCS Semifinal 1 (win)   \n",
       "1685  e7ce7680-f058-11ee-89df-6558e107cb95                 Team TBD   \n",
       "1686  e7ce7680-f058-11ee-89df-6558e107cb95                 Team TBD   \n",
       "1687                                  None         Peach Bowl (win)   \n",
       "\n",
       "      home_game_number  \n",
       "0                  1.0  \n",
       "1                  1.0  \n",
       "2                  1.0  \n",
       "3                  1.0  \n",
       "4                  1.0  \n",
       "...                ...  \n",
       "1683               NaN  \n",
       "1684               NaN  \n",
       "1685               NaN  \n",
       "1686               NaN  \n",
       "1687               NaN  \n",
       "\n",
       "[1688 rows x 3 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'scheduled' column to datetime\n",
    "df_schedule[\"scheduled\"] = pd.to_datetime(df_schedule[\"scheduled\"], errors=\"coerce\")\n",
    "\n",
    "# Convert latitude and longitude to float\n",
    "df_schedule[\"venue_lat\"] = pd.to_numeric(df_schedule[\"venue_lat\"], errors=\"coerce\")\n",
    "df_schedule[\"venue_lng\"] = pd.to_numeric(df_schedule[\"venue_lng\"], errors=\"coerce\")\n",
    "\n",
    "df_schedule.to_csv(\"schedule.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "df_schedule.info()\n",
    "\n",
    "df_schedule[[\"home_id\", \"home_name\", \"home_game_number\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32a4fc",
   "metadata": {},
   "source": [
    "# SEASONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76c7514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load JSON file into a variable\n",
    "with open(\"seasons.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    seasons = json.load(f)\n",
    "    data = seasons \n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "league = data.get(\"league\", {})\n",
    "\n",
    "for season in data.get(\"seasons\", []):\n",
    "\n",
    "    row = {\n",
    "        # ----- LEAGUE INFO -----\n",
    "        \"league_id\": league.get(\"id\"),\n",
    "        \"league_name\": league.get(\"name\"),\n",
    "        \"league_alias\": league.get(\"alias\"),\n",
    "\n",
    "        # ----- SEASON INFO -----\n",
    "        \"season_id\": season.get(\"id\"),\n",
    "        \"season_year\": season.get(\"year\"),\n",
    "        \"start_date\": season.get(\"start_date\"),\n",
    "        \"end_date\": season.get(\"end_date\"),\n",
    "        \"status\": season.get(\"status\"),\n",
    "\n",
    "        # ----- FLATTEN NESTED \"type\" -----\n",
    "        \"type_code\": season.get(\"type\", {}).get(\"code\"),\n",
    "    }\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_seasons = pd.DataFrame(rows)\n",
    "\n",
    "# Show complete output\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# df_seasons.to_csv(\"seasons.csv\", index=False, encoding=\"utf-8\")\n",
    "# df_seasons.info()\n",
    "# df_seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "438b5a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   league_id     13 non-null     object        \n",
      " 1   league_name   13 non-null     object        \n",
      " 2   league_alias  13 non-null     object        \n",
      " 3   season_id     13 non-null     object        \n",
      " 4   season_year   13 non-null     int64         \n",
      " 5   start_date    13 non-null     datetime64[ns]\n",
      " 6   end_date      13 non-null     datetime64[ns]\n",
      " 7   status        13 non-null     object        \n",
      " 8   type_code     13 non-null     object        \n",
      "dtypes: datetime64[ns](2), int64(1), object(6)\n",
      "memory usage: 1.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_seasons[\"start_date\"] = pd.to_datetime(df_seasons[\"start_date\"])\n",
    "df_seasons[\"end_date\"] = pd.to_datetime(df_seasons[\"end_date\"])\n",
    "\n",
    "df_seasons.to_csv(\"seasons.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "df_seasons.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89abfa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: all_df_info.txt\n"
     ]
    }
   ],
   "source": [
    "# df_player_profile.info()\n",
    "# df_rankings.info()\n",
    "# df_roster.info()\n",
    "# df_schedule.info()\n",
    "# df_seasons.info()\n",
    "\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def df_info_to_string(df):\n",
    "    buffer = StringIO()\n",
    "    df.info(buf=buffer)\n",
    "    return buffer.getvalue()\n",
    "\n",
    "# Collect info sections\n",
    "info_text = \"\"\n",
    "\n",
    "info_text += \"===== PLAYER PROFILE INFO =====\\n\"\n",
    "info_text += df_info_to_string(df_player_profile) + \"\\n\\n\"\n",
    "\n",
    "info_text += \"===== RANKINGS INFO =====\\n\"\n",
    "info_text += df_info_to_string(df_rankings) + \"\\n\\n\"\n",
    "\n",
    "info_text += \"===== ROSTER INFO =====\\n\"\n",
    "info_text += df_info_to_string(df_roster) + \"\\n\\n\"\n",
    "\n",
    "info_text += \"===== SEASON SCHEDULE INFO =====\\n\"\n",
    "info_text += df_info_to_string(df_schedule) + \"\\n\\n\"\n",
    "\n",
    "info_text += \"===== SEASONS INFO =====\\n\"\n",
    "info_text += df_info_to_string(df_seasons) + \"\\n\\n\"\n",
    "\n",
    "# Save to one file\n",
    "with open(\"all_df_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(info_text)\n",
    "\n",
    "print(\"Saved: all_df_info.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77ab404",
   "metadata": {},
   "source": [
    "Load Order : \n",
    "\n",
    "1ï¸âƒ£ conferences  \n",
    "2ï¸âƒ£ divisions  \n",
    "3ï¸âƒ£ venues  \n",
    "4ï¸âƒ£ teams  \n",
    "5ï¸âƒ£ seasons  \n",
    "6ï¸âƒ£ players  \n",
    "7ï¸âƒ£ player_statistics  \n",
    "8ï¸âƒ£ rankings  \n",
    "9ï¸âƒ£ coaches (optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f1002",
   "metadata": {},
   "source": [
    "# LOAD CONFERENCES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b34a282a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” conferences loaded\n"
     ]
    }
   ],
   "source": [
    "df_conferences = df_roster[[\n",
    "    \"conference_id\",\n",
    "    \"conference_name\",\n",
    "    \"conference_alias\"\n",
    "]].drop_duplicates()\n",
    "\n",
    "df_conferences = df_conferences.where(pd.notnull(df_conferences), None)\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "INSERT INTO conferences (conference_id, name, alias)\n",
    "VALUES (%s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(insert_sql, df_conferences.values.tolist())\n",
    "conn.commit()\n",
    "print(\"âœ” conferences loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebc820e",
   "metadata": {},
   "source": [
    "# LOAD DIVISIONS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee5f3923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” divisions loaded\n"
     ]
    }
   ],
   "source": [
    "df_divisions = df_roster[[\n",
    "    \"division_id\",\n",
    "    \"division_name\",\n",
    "    \"division_alias\"\n",
    "]].drop_duplicates()\n",
    "\n",
    "df_divisions = df_divisions.where(pd.notnull(df_divisions), None)\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "INSERT INTO divisions (division_id, name, alias)\n",
    "VALUES (%s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(insert_sql, df_divisions.values.tolist())\n",
    "conn.commit()\n",
    "print(\"âœ” divisions loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0b0fe8",
   "metadata": {},
   "source": [
    "# LOAD VENUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "476fc788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” venues loaded\n"
     ]
    }
   ],
   "source": [
    "venue_cols = [\n",
    "    \"venue_id\", \"venue_name\", \"venue_city\", \"venue_state\",\n",
    "    \"venue_country\", \"venue_zip\", \"venue_address\",\n",
    "    \"venue_capacity\", \"venue_surface\", \"venue_roof\",\n",
    "    \"venue_lat\", \"venue_lng\"\n",
    "]\n",
    "\n",
    "df_venues = df_schedule[venue_cols].dropna(subset=[\"venue_id\"]).drop_duplicates()\n",
    "\n",
    "df_venues = df_venues.where(pd.notnull(df_venues), None)\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "INSERT INTO venues (\n",
    "    venue_id, name, city, state, country, zip,\n",
    "    address, capacity, surface, roof_type,\n",
    "    latitude, longitude\n",
    ") VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(insert_sql, df_venues.values.tolist())\n",
    "conn.commit()\n",
    "print(\"âœ” venues loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b16f2f",
   "metadata": {},
   "source": [
    "# LOAD TEAMS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c38bd73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                team_id market                      name  \\\n",
      "0  0dd26ea7-79fb-4ea8-bf48-7c31108e14a3   None     Kansas State Wildcats   \n",
      "1  d335c726-44aa-4b69-8271-59d42d691cba   None       Iowa State Cyclones   \n",
      "2  deea4446-2bee-4144-96bc-9f1e8ccceee8   None   Nicholls State Colonels   \n",
      "3  5cecc23b-cb18-49f2-85ef-3717063e9dca   None  Incarnate Word Cardinals   \n",
      "4  5f105ef1-4d01-45a5-bfbb-497ee86a8eba   None               UNLV Rebels   \n",
      "\n",
      "  alias conference_id division_id                              venue_id  \n",
      "0   KSU          None        None  c63bd111-d94a-42e1-bd95-cbb74103552c  \n",
      "1   ISU          None        None  98612a89-835b-4ee3-a44d-4841b918262a  \n",
      "2  NICH          None        None  c6323dc8-9582-4a87-8c37-2ffb2a5fb548  \n",
      "3    IW          None        None  cb9b2edd-bb4d-4011-9cce-59bebb202567  \n",
      "4  UNLV          None        None  15e8cfc6-bc73-4767-b357-cb54778e12cf  \n",
      "TOTAL TEAMS FOUND: 317\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# --------------------------------------\n",
    "# LOAD SEASON SCHEDULE\n",
    "# --------------------------------------\n",
    "with open(\"sched.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "teams = {}\n",
    "\n",
    "# --------------------------------------\n",
    "# EXTRACT TEAMS FROM EVERY GAME (home + away)\n",
    "# --------------------------------------\n",
    "for week in data.get(\"weeks\", []):\n",
    "    for game in week.get(\"games\", []):\n",
    "\n",
    "        # Home team\n",
    "        home = game.get(\"home\", {})\n",
    "        if \"id\" in home:\n",
    "            teams[home[\"id\"]] = {\n",
    "                \"team_id\": home.get(\"id\"),\n",
    "                \"market\": home.get(\"market\"),\n",
    "                \"name\": home.get(\"name\"),\n",
    "                \"alias\": home.get(\"alias\"),\n",
    "                \"conference_id\": home.get(\"conference\", {}).get(\"id\"),\n",
    "                \"division_id\": home.get(\"division\", {}).get(\"id\"),\n",
    "                \"venue_id\": game.get(\"venue\", {}).get(\"id\")\n",
    "            }\n",
    "\n",
    "        # Away team\n",
    "        away = game.get(\"away\", {})\n",
    "        if \"id\" in away:\n",
    "            teams[away[\"id\"]] = {\n",
    "                \"team_id\": away.get(\"id\"),\n",
    "                \"market\": away.get(\"market\"),\n",
    "                \"name\": away.get(\"name\"),\n",
    "                \"alias\": away.get(\"alias\"),\n",
    "                \"conference_id\": away.get(\"conference\", {}).get(\"id\"),\n",
    "                \"division_id\": away.get(\"division\", {}).get(\"id\"),\n",
    "                \"venue_id\": game.get(\"venue\", {}).get(\"id\")\n",
    "            }\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_teams = pd.DataFrame(list(teams.values()))\n",
    "\n",
    "# Replace NaN with None\n",
    "df_teams = df_teams.where(pd.notnull(df_teams), None)\n",
    "\n",
    "print(df_teams.head())\n",
    "print(\"TOTAL TEAMS FOUND:\", len(df_teams))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "be51807f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” ALL TEAMS INSERTED\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Alys@003!\",\n",
    "    database=\"ncaafb_db\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "INSERT IGNORE INTO teams (\n",
    "    team_id, market, name, alias,\n",
    "    conference_id, division_id, venue_id\n",
    ") VALUES (%s,%s,%s,%s,%s,%s,%s)\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(insert_sql, df_teams.values.tolist())\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"âœ” ALL TEAMS INSERTED\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb2d439",
   "metadata": {},
   "source": [
    "# LOAD SEASONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62be1a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded seasons Table!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "df = df_seasons.copy()\n",
    "\n",
    "# Clean\n",
    "df = df.rename(columns={\"season_year\": \"year\"})\n",
    "df[\"start_date\"] = df[\"start_date\"].dt.date.astype(str)\n",
    "df[\"end_date\"] = df[\"end_date\"].dt.date.astype(str)\n",
    "df = df.where(pd.notnull(df), None)\n",
    "\n",
    "# Keep only required columns\n",
    "df = df[[\"season_id\", \"year\", \"start_date\", \"end_date\", \"status\", \"type_code\"]]\n",
    "\n",
    "# Connect\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Alys@003!\",\n",
    "    database=\"ncaafb_db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "INSERT IGNORE INTO seasons (\n",
    "    season_id, year, start_date, end_date, status, type_code\n",
    ") VALUES (%s, %s, %s, %s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(insert_sql, df.values.tolist())\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"âœ… Loaded seasons Table!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce2631",
   "metadata": {},
   "source": [
    "# LOAD PLAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f094eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 125 players into PLAYERS table!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_17736\\3218272768.py:52: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  df_players[col] = df_players[f\"{col}_p\"].combine_first(df_players[f\"{col}_r\"])\n",
      "C:\\Users\\Paul\\AppData\\Local\\Temp\\ipykernel_17736\\3218272768.py:52: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  df_players[col] = df_players[f\"{col}_p\"].combine_first(df_players[f\"{col}_r\"])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Copy dataframes\n",
    "df_roster_copy = df_roster.copy()\n",
    "df_profile_copy = df_player_profile.copy()\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 1. Rename columns from roster to match table\n",
    "# ---------------------------------------------\n",
    "df_roster_players = df_roster_copy.rename(columns={\n",
    "    \"player_id\": \"player_id\",\n",
    "    \"player_first_name\": \"first_name\",\n",
    "    \"player_last_name\": \"last_name\",\n",
    "    \"player_abbr_name\": \"abbr_name\",\n",
    "    \"player_birth_place\": \"birth_place\",\n",
    "    \"player_position\": \"position\",\n",
    "    \"player_height\": \"height\",\n",
    "    \"player_weight\": \"weight\",\n",
    "    \"player_status\": \"status\",\n",
    "    \"player_eligibility\": \"eligibility\",\n",
    "    \"team_id\": \"team_id\"\n",
    "})\n",
    "\n",
    "# Keep only required columns\n",
    "df_roster_players = df_roster_players[[\n",
    "    \"player_id\", \"first_name\", \"last_name\", \"abbr_name\",\n",
    "    \"birth_place\", \"position\", \"height\", \"weight\",\n",
    "    \"status\", \"eligibility\", \"team_id\"\n",
    "]]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2. Merge profile data (priority: profile > roster)\n",
    "# ---------------------------------------------\n",
    "df_profile_small = df_profile_copy[[\n",
    "    \"player_id\", \"first_name\", \"last_name\", \"abbr_name\",\n",
    "    \"birth_place\", \"position\", \"height\", \"weight\",\n",
    "    \"status\", \"eligibility\"\n",
    "]]\n",
    "\n",
    "df_players = df_roster_players.merge(\n",
    "    df_profile_small,\n",
    "    on=\"player_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_r\", \"_p\")\n",
    ")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3. If profile has better data â†’ overwrite\n",
    "# ---------------------------------------------\n",
    "for col in [\"first_name\", \"last_name\", \"abbr_name\", \"birth_place\",\n",
    "            \"position\", \"height\", \"weight\", \"status\", \"eligibility\"]:\n",
    "    df_players[col] = df_players[f\"{col}_p\"].combine_first(df_players[f\"{col}_r\"])\n",
    "\n",
    "# Remove merged temp columns\n",
    "df_players = df_players[[\n",
    "    \"player_id\", \"first_name\", \"last_name\", \"abbr_name\",\n",
    "    \"birth_place\", \"position\", \"height\", \"weight\",\n",
    "    \"status\", \"eligibility\", \"team_id\"\n",
    "]]\n",
    "\n",
    "# Clean df_players Before Insert\n",
    "df_players = df_players.where(pd.notnull(df_players), None)\n",
    "\n",
    "\n",
    "# Insert Into MySQL Using INSERT IGNORE\n",
    "import mysql.connector\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Alys@003!\",\n",
    "    database=\"ncaafb_db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "INSERT IGNORE INTO players (\n",
    "    player_id, first_name, last_name, abbr_name,\n",
    "    birth_place, position, height, weight,\n",
    "    status, eligibility, team_id\n",
    ") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(insert_sql, df_players.values.tolist())\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ… Loaded {len(df_players)} players into PLAYERS table!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b53208",
   "metadata": {},
   "source": [
    "# PLAYER STATISTICS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "636c2b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Player_Statistics loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "\n",
    "# Make a copy\n",
    "df_stats = df_player_statistics.copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Force convert NaN â†’ None\n",
    "# -----------------------------\n",
    "df_stats = df_stats.replace({np.nan: None})\n",
    "df_stats = df_stats.where(pd.notnull(df_stats), None)\n",
    "\n",
    "# Convert IDs to strings\n",
    "df_stats[\"player_id\"] = df_stats[\"player_id\"].astype(str)\n",
    "df_stats[\"team_id\"]   = df_stats[\"team_id\"].astype(str)\n",
    "df_stats[\"season_id\"] = df_stats[\"season_id\"].astype(str)\n",
    "\n",
    "# Convert numeric NaN â†’ None\n",
    "num_cols = [\n",
    "    \"games_played\", \"games_started\",\n",
    "    \"rushing_yards\", \"rushing_touchdowns\",\n",
    "    \"receiving_yards\", \"receiving_touchdowns\",\n",
    "    \"kick_return_yards\", \"fumbles\"\n",
    "]\n",
    "\n",
    "for col in num_cols:\n",
    "    df_stats[col] = df_stats[col].astype(object).where(df_stats[col].notna(), None)\n",
    "\n",
    "# -----------------------------\n",
    "# MySQL Insert\n",
    "# -----------------------------\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Alys@003!\",\n",
    "    database=\"ncaafb_db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "INSERT IGNORE INTO player_statistics (\n",
    "    player_id,\n",
    "    team_id,\n",
    "    season_id,\n",
    "    games_played,\n",
    "    games_started,\n",
    "    rushing_yards,\n",
    "    rushing_touchdowns,\n",
    "    receiving_yards,\n",
    "    receiving_touchdowns,\n",
    "    kick_return_yards,\n",
    "    fumbles\n",
    ") VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(insert_sql, df_stats.values.tolist())\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"âœ… Player_Statistics loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d87d66f",
   "metadata": {},
   "source": [
    "# RANKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "27e769b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rankings loaded successfully! Inserted 25 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 1) PREPARE DATAFRAME\n",
    "# ============================================================\n",
    "\n",
    "df_r = df_rankings.copy()\n",
    "\n",
    "# ----- Convert datetime -----\n",
    "df_r[\"effective_time\"] = pd.to_datetime(df_r[\"effective_time\"])\n",
    "\n",
    "# Safe timezone removal\n",
    "try:\n",
    "    df_r[\"effective_time\"] = df_r[\"effective_time\"].dt.tz_convert(None)\n",
    "except TypeError:\n",
    "    pass  # Already tz-naive\n",
    "\n",
    "# ============================================================\n",
    "# 2) FK LOOKUP â†’ season_id\n",
    "# ============================================================\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Alys@003!\",\n",
    "    database=\"ncaafb_db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT season_id, year FROM seasons\")\n",
    "season_lookup = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "df_r[\"season_id\"] = df_r[\"season\"].map(season_lookup)\n",
    "\n",
    "# ============================================================\n",
    "# 3) ADD MISSING COLUMNS (NOT PROVIDED BY API)\n",
    "# ============================================================\n",
    "\n",
    "df_r[\"prev_rank\"] = None\n",
    "df_r[\"wins\"] = None\n",
    "df_r[\"losses\"] = None\n",
    "df_r[\"ties\"] = None\n",
    "\n",
    "# ============================================================\n",
    "# 4) CLEANING â€” NaN â†’ None\n",
    "# ============================================================\n",
    "\n",
    "df_r = df_r.replace({np.nan: None})\n",
    "df_r = df_r.where(pd.notnull(df_r), None)\n",
    "\n",
    "# Convert essential columns to correct datatypes\n",
    "df_r[\"poll_id\"] = df_r[\"poll_id\"].astype(str)\n",
    "df_r[\"poll_name\"] = df_r[\"poll_name\"].astype(str)\n",
    "df_r[\"team_id\"] = df_r[\"team_id\"].astype(str)\n",
    "\n",
    "# Numeric safe conversion\n",
    "int_cols = [\"week\", \"rank\", \"points\", \"first_place_votes\"]\n",
    "for col in int_cols:\n",
    "    df_r[col] = df_r[col].astype(object).where(df_r[col].notna(), None)\n",
    "\n",
    "# ============================================================\n",
    "# 5) BUILD ROWS (MATCH TABLE COLUMNS EXACTLY)\n",
    "# ============================================================\n",
    "\n",
    "rows = []\n",
    "for _, r in df_r.iterrows():\n",
    "    rows.append([\n",
    "        r[\"poll_id\"],\n",
    "        r[\"poll_name\"],\n",
    "        r[\"season_id\"],\n",
    "        r[\"week\"],\n",
    "        r[\"effective_time\"].to_pydatetime() if r[\"effective_time\"] else None,\n",
    "        r[\"team_id\"],\n",
    "        r[\"rank\"],\n",
    "        r[\"prev_rank\"],\n",
    "        r[\"points\"],\n",
    "        r[\"first_place_votes\"],\n",
    "        r[\"wins\"],\n",
    "        r[\"losses\"],\n",
    "        r[\"ties\"]\n",
    "    ])\n",
    "\n",
    "# ============================================================\n",
    "# 6) INSERT INTO DATABASE\n",
    "# ranking_id is AUTO_INCREMENT â†’ NOT included\n",
    "# ============================================================\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "INSERT IGNORE INTO rankings (\n",
    "    poll_id,\n",
    "    poll_name,\n",
    "    season_id,\n",
    "    week,\n",
    "    effective_time,\n",
    "    team_id,\n",
    "    `rank`,\n",
    "    prev_rank,\n",
    "    points,\n",
    "    fp_votes,\n",
    "    wins,\n",
    "    losses,\n",
    "    ties\n",
    ") VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(insert_sql, rows)\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ… Rankings loaded successfully! Inserted {len(rows)} rows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0a072",
   "metadata": {},
   "source": [
    "# COACHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0a805d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Coaches table loaded successfully! Inserted 1 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 1) PREPARE DATAFRAME\n",
    "# ============================================================\n",
    "\n",
    "df_coaches = df_roster.copy()\n",
    "\n",
    "# Select only required columns\n",
    "df_coaches = df_coaches[[\n",
    "    \"coach_id\",\n",
    "    \"coach_full_name\",\n",
    "    \"coach_position\",\n",
    "    \"team_id\"\n",
    "]]\n",
    "\n",
    "# Remove duplicates (one coach per team)\n",
    "df_coaches = df_coaches.drop_duplicates(subset=[\"coach_id\"])\n",
    "\n",
    "# ============================================================\n",
    "# 2) CLEANING â†’ NaN â†’ None\n",
    "# ============================================================\n",
    "\n",
    "df_coaches = df_coaches.replace({np.nan: None})\n",
    "df_coaches = df_coaches.where(pd.notnull(df_coaches), None)\n",
    "\n",
    "# Convert ID columns to strings\n",
    "df_coaches[\"coach_id\"] = df_coaches[\"coach_id\"].astype(str)\n",
    "df_coaches[\"team_id\"]  = df_coaches[\"team_id\"].astype(str)\n",
    "\n",
    "# ============================================================\n",
    "# 3) CONNECT TO MYSQL\n",
    "# ============================================================\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Alys@003!\",\n",
    "    database=\"ncaafb_db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ============================================================\n",
    "# 4) INSERT SQL (coach_id is PK)\n",
    "# ============================================================\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "INSERT IGNORE INTO coaches (\n",
    "    coach_id,\n",
    "    full_name,\n",
    "    position,\n",
    "    team_id\n",
    ") VALUES (%s, %s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "# Convert dataframe to list of tuples\n",
    "rows = df_coaches.values.tolist()\n",
    "\n",
    "# ============================================================\n",
    "# 5) EXECUTE INSERT\n",
    "# ============================================================\n",
    "\n",
    "cursor.executemany(insert_sql, rows)\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ… Coaches table loaded successfully! Inserted {len(rows)} rows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5def9e",
   "metadata": {},
   "source": [
    "# How many home vs away games were played per team in a season?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dc13931d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              season_id  season_year  \\\n",
      "0  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025   \n",
      "1  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025   \n",
      "2  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025   \n",
      "3  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025   \n",
      "4  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025   \n",
      "\n",
      "                                team_id                 team_name  is_home  \\\n",
      "0  0dd26ea7-79fb-4ea8-bf48-7c31108e14a3     Kansas State Wildcats     True   \n",
      "1  d335c726-44aa-4b69-8271-59d42d691cba       Iowa State Cyclones    False   \n",
      "2  deea4446-2bee-4144-96bc-9f1e8ccceee8   Nicholls State Colonels     True   \n",
      "3  5cecc23b-cb18-49f2-85ef-3717063e9dca  Incarnate Word Cardinals    False   \n",
      "4  5f105ef1-4d01-45a5-bfbb-497ee86a8eba               UNLV Rebels     True   \n",
      "\n",
      "                                game_id  \n",
      "0  ff0532c8-cc0d-473a-b47f-421eccf4d427  \n",
      "1  ff0532c8-cc0d-473a-b47f-421eccf4d427  \n",
      "2  7770d00f-8df8-4629-935e-d22b8592a6b5  \n",
      "3  7770d00f-8df8-4629-935e-d22b8592a6b5  \n",
      "4  31adc52f-a271-4e44-a252-7f6093d08be6  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3352 entries, 0 to 3351\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   season_id    3352 non-null   object\n",
      " 1   season_year  3352 non-null   int64 \n",
      " 2   team_id      3352 non-null   object\n",
      " 3   team_name    3352 non-null   object\n",
      " 4   is_home      3352 non-null   bool  \n",
      " 5   game_id      3352 non-null   object\n",
      "dtypes: bool(1), int64(1), object(4)\n",
      "memory usage: 134.3+ KB\n",
      "None\n",
      "is_home                                                             away_games  \\\n",
      "team_id                              team_name                                   \n",
      "00cbe6eb-c9c2-43d4-8158-6952066f0d2b William & Mary Tribe                    6   \n",
      "00fd8418-0e62-4366-9a2a-d5f72850066c Arizona State Sun Devils                5   \n",
      "018e079b-3848-49bf-8fc6-2d44bbc120a0 Stetson Hatters                         5   \n",
      "02cd61b6-2dad-4b3d-94cd-1c1c3cdbf3ad New Mexico Lobos                        6   \n",
      "034ac81a-311c-49f4-8c45-ddcef7777bdc North Carolina State Wolfpack           5   \n",
      "...                                                                        ...   \n",
      "fbd30b5d-6d84-49f7-abf1-c2c73f9e2458 Princeton Tigers                        5   \n",
      "fce005d9-c29b-4f9c-836b-92a25e765f28 Delaware State Hornets                  6   \n",
      "fefae711-b307-4fd4-b0d2-c9df51f5ae1c Montana State Bobcats                   5   \n",
      "ff330f91-bacc-4c43-b14e-604c58115ebd Cal Poly Mustangs                       7   \n",
      "ffca4209-dbfa-4597-b25a-ed19bb351037 LSU Tigers                              5   \n",
      "\n",
      "is_home                                                             home_games  \n",
      "team_id                              team_name                                  \n",
      "00cbe6eb-c9c2-43d4-8158-6952066f0d2b William & Mary Tribe                    6  \n",
      "00fd8418-0e62-4366-9a2a-d5f72850066c Arizona State Sun Devils                7  \n",
      "018e079b-3848-49bf-8fc6-2d44bbc120a0 Stetson Hatters                         7  \n",
      "02cd61b6-2dad-4b3d-94cd-1c1c3cdbf3ad New Mexico Lobos                        6  \n",
      "034ac81a-311c-49f4-8c45-ddcef7777bdc North Carolina State Wolfpack           7  \n",
      "...                                                                        ...  \n",
      "fbd30b5d-6d84-49f7-abf1-c2c73f9e2458 Princeton Tigers                        5  \n",
      "fce005d9-c29b-4f9c-836b-92a25e765f28 Delaware State Hornets                  6  \n",
      "fefae711-b307-4fd4-b0d2-c9df51f5ae1c Montana State Bobcats                   7  \n",
      "ff330f91-bacc-4c43-b14e-604c58115ebd Cal Poly Mustangs                       5  \n",
      "ffca4209-dbfa-4597-b25a-ed19bb351037 LSU Tigers                              7  \n",
      "\n",
      "[317 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------\n",
    "# Load JSON\n",
    "# ---------------------------------------\n",
    "with open(\"sched.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "season_id = data.get(\"id\")\n",
    "season_year = data.get(\"year\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Loop through all weeks and all games\n",
    "# ---------------------------------------------------\n",
    "for week in data.get(\"weeks\", []):\n",
    "    for game in week.get(\"games\", []):\n",
    "\n",
    "        game_id = game.get(\"id\")\n",
    "\n",
    "        # ---------- HOME TEAM ----------\n",
    "        home = game.get(\"home\", {})\n",
    "        home_team_id = home.get(\"id\")\n",
    "        home_team_name = home.get(\"name\")\n",
    "\n",
    "        if home_team_id:\n",
    "            rows.append({\n",
    "                \"season_id\": season_id,\n",
    "                \"season_year\": season_year,\n",
    "                \"team_id\": home_team_id,\n",
    "                \"team_name\": home_team_name,\n",
    "                \"is_home\": True,\n",
    "                \"game_id\": game_id\n",
    "            })\n",
    "\n",
    "        # ---------- AWAY TEAM ----------\n",
    "        away = game.get(\"away\", {})\n",
    "        away_team_id = away.get(\"id\")\n",
    "        away_team_name = away.get(\"name\")\n",
    "\n",
    "        if away_team_id:\n",
    "            rows.append({\n",
    "                \"season_id\": season_id,\n",
    "                \"season_year\": season_year,\n",
    "                \"team_id\": away_team_id,\n",
    "                \"team_name\": away_team_name,\n",
    "                \"is_home\": False,\n",
    "                \"game_id\": game_id\n",
    "            })\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Convert to DataFrame\n",
    "# ---------------------------------------------------\n",
    "df_home_away = pd.DataFrame(rows)\n",
    "\n",
    "print(df_home_away.head())\n",
    "print(df_home_away.info())\n",
    "\n",
    "\n",
    "summary = df_home_away.groupby([\"team_id\", \"team_name\", \"is_home\"]) \\\n",
    "                      .size().unstack(fill_value=0) \\\n",
    "                      .rename(columns={True: \"home_games\", False: \"away_games\"})\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5cc42882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… team_game_counts table loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = df_home_away.copy()\n",
    "\n",
    "# --- Clean ---\n",
    "df = df.replace({np.nan: None})\n",
    "df = df.where(pd.notnull(df), None)\n",
    "\n",
    "# --- Ensure correct datatypes ---\n",
    "df[\"season_id\"] = df[\"season_id\"].astype(str)\n",
    "df[\"season_year\"] = df[\"season_year\"].astype(int)\n",
    "df[\"team_id\"] = df[\"team_id\"].astype(str)\n",
    "df[\"team_name\"] = df[\"team_name\"].astype(str)\n",
    "df[\"game_id\"] = df[\"game_id\"].astype(str)\n",
    "df[\"is_home\"] = df[\"is_home\"].astype(bool)\n",
    "\n",
    "# --- FORCE correct column order to match INSERT SQL ---\n",
    "df = df[[\n",
    "    \"season_id\",\n",
    "    \"season_year\",\n",
    "    \"team_id\",\n",
    "    \"team_name\",\n",
    "    \"game_id\",\n",
    "    \"is_home\"\n",
    "]]\n",
    "\n",
    "# --- Connect to MySQL ---\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Alys@003!\",\n",
    "    database=\"ncaafb_db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# --- Insert SQL ---\n",
    "insert_sql = \"\"\"\n",
    "INSERT INTO team_game_counts (\n",
    "    season_id,\n",
    "    season_year,\n",
    "    team_id,\n",
    "    team_name,\n",
    "    game_id,\n",
    "    is_home\n",
    ") VALUES (%s, %s, %s, %s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "rows = df.values.tolist()\n",
    "\n",
    "cursor.executemany(insert_sql, rows)\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"âœ… team_game_counts table loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56845a73",
   "metadata": {},
   "source": [
    "# MOST USED VENUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ef8ca9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venue DataFrame created!\n",
      "                              season_id  season_year season_type  \\\n",
      "0  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
      "1  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
      "2  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
      "3  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
      "4  754e4990-efc7-11ef-bb2a-5d2d22b9215e         2025         REG   \n",
      "\n",
      "                                game_id                              venue_id  \\\n",
      "0  ff0532c8-cc0d-473a-b47f-421eccf4d427  c98ace28-f447-46f4-a0d1-af3b94e00cc3   \n",
      "1  7770d00f-8df8-4629-935e-d22b8592a6b5  00828546-ccd4-4f57-89b5-3ceeee59b6df   \n",
      "2  31adc52f-a271-4e44-a252-7f6093d08be6  ca45b851-0906-4762-af04-16a96215ca25   \n",
      "3  e82376a4-dbbf-4d70-afb0-fbd6a54553f4  9c949dc9-c50d-4231-91b2-8b8d9a56e26e   \n",
      "4  dfcb530d-3329-4624-8428-c71eea57c449  0befa6a6-87d9-43ad-b2a3-ecc00bca9a1a   \n",
      "\n",
      "                                venue_name venue_city venue_state  \\\n",
      "0                            Aviva Stadium     Dublin        None   \n",
      "1  Manning Field at John L. Guidry Stadium  Thibodaux          LA   \n",
      "2                        Allegiant Stadium  Las Vegas          NV   \n",
      "3                        Hillsboro Stadium  Hillsboro          OR   \n",
      "4      David Booth Kansas Memorial Stadium   Lawrence          KS   \n",
      "\n",
      "  venue_country venue_zip         venue_address  venue_capacity venue_surface  \\\n",
      "0           IRL      None     62 Lansdowne Road         49000.0          turf   \n",
      "1           USA     70301      906 E 1st Street         10500.0    artificial   \n",
      "2           USA     89118     3333 Al Davis Way         65000.0    artificial   \n",
      "3           USA     97124  4450 NW 229th Avenue          7600.0    artificial   \n",
      "4           USA     66044     1101 Maine Street         50071.0    artificial   \n",
      "\n",
      "  venue_roof_type venue_lat  venue_lng  \n",
      "0         outdoor   53.3353    -6.2284  \n",
      "1         outdoor   29.7851   -90.8024  \n",
      "2            dome   36.0909  -115.1833  \n",
      "3         outdoor   45.5544  -122.9070  \n",
      "4         outdoor   38.9629   -95.2464  \n",
      "\n",
      "Most Used Venues:\n",
      "                                 venue_id                    venue_name  \\\n",
      "59   280bf6ac-33d9-4e2c-a4bd-af2612f61d00             Hard Rock Stadium   \n",
      "211  bd84c6aa-cafb-4ecf-b21f-44253c99c854          Shell Energy Stadium   \n",
      "131  74d2b383-1122-4b5e-ac70-5c0391d5e760                Nissan Stadium   \n",
      "272  f02c9eb2-0b21-4cea-9f44-7bfac957f7ca  Simmons Bank Liberty Stadium   \n",
      "25   0d3004a2-736f-42c2-973b-31e1391404f4               Arizona Stadium   \n",
      "\n",
      "        venue_city venue_state  games_hosted  \n",
      "59   Miami Gardens          FL            11  \n",
      "211        Houston          TX            11  \n",
      "131      Nashville          TN             9  \n",
      "272        Memphis          TN             8  \n",
      "25          Tucson          AZ             8  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Load season_schedule JSON\n",
    "# ---------------------------------------------------------\n",
    "with open(\"sched.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "rows = []\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Loop through weeks â†’ games â†’ venue\n",
    "# ---------------------------------------------------------\n",
    "for week in data.get(\"weeks\", []):\n",
    "    for game in week.get(\"games\", []):\n",
    "\n",
    "        venue = game.get(\"venue\", {})\n",
    "\n",
    "        rows.append({\n",
    "            \"season_id\": data.get(\"id\"),\n",
    "            \"season_year\": data.get(\"year\"),\n",
    "            \"season_type\": data.get(\"type\"),\n",
    "\n",
    "            \"game_id\": game.get(\"id\"),\n",
    "\n",
    "            # -------- VENUE FIELDS ----------\n",
    "            \"venue_id\": venue.get(\"id\"),\n",
    "            \"venue_name\": venue.get(\"name\"),\n",
    "            \"venue_city\": venue.get(\"city\"),\n",
    "            \"venue_state\": venue.get(\"state\"),\n",
    "            \"venue_country\": venue.get(\"country\"),\n",
    "            \"venue_zip\": venue.get(\"zip\"),\n",
    "            \"venue_address\": venue.get(\"address\"),\n",
    "            \"venue_capacity\": venue.get(\"capacity\"),\n",
    "            \"venue_surface\": venue.get(\"surface\"),\n",
    "            \"venue_roof_type\": venue.get(\"roof_type\"),\n",
    "\n",
    "            # venue.location\n",
    "            \"venue_lat\": (venue.get(\"location\") or {}).get(\"lat\"),\n",
    "            \"venue_lng\": (venue.get(\"location\") or {}).get(\"lng\"),\n",
    "        })\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Convert to DataFrame\n",
    "# ---------------------------------------------------------\n",
    "df_venues = pd.DataFrame(rows)\n",
    "\n",
    "print(\"Venue DataFrame created!\")\n",
    "print(df_venues.head())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Group to compute MOST USED VENUES\n",
    "# ---------------------------------------------------------\n",
    "df_most_used = (\n",
    "    df_venues.groupby([\"venue_id\", \"venue_name\", \"venue_city\", \"venue_state\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"games_hosted\")\n",
    "    .sort_values(\"games_hosted\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\nMost Used Venues:\")\n",
    "print(df_most_used.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1c9b6bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… most_used_venues table loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# df_most_used is already generated earlier\n",
    "# ----------------------------------------------------\n",
    "df = df_most_used.copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Replace NaN â†’ None\n",
    "# -----------------------------\n",
    "df = df.replace({np.nan: None})\n",
    "df = df.where(pd.notnull(df), None)\n",
    "\n",
    "# -----------------------------\n",
    "# Convert fields to correct types\n",
    "# -----------------------------\n",
    "df[\"venue_id\"] = df[\"venue_id\"].astype(str)\n",
    "df[\"venue_name\"] = df[\"venue_name\"].astype(str)\n",
    "df[\"venue_city\"] = df[\"venue_city\"].astype(str)\n",
    "df[\"venue_state\"] = df[\"venue_state\"].astype(str)\n",
    "df[\"games_hosted\"] = df[\"games_hosted\"].astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# Open MySQL Connection\n",
    "# -----------------------------\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Alys@003!\",   # change if needed\n",
    "    database=\"ncaafb_db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# -----------------------------\n",
    "# Insert Query\n",
    "# -----------------------------\n",
    "insert_sql = \"\"\"\n",
    "INSERT INTO most_used_venues (\n",
    "    venue_id,\n",
    "    venue_name,\n",
    "    venue_city,\n",
    "    venue_state,\n",
    "    games_hosted\n",
    ") VALUES (%s, %s, %s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "# Build list of rows\n",
    "rows = df.values.tolist()\n",
    "\n",
    "# Load into DB\n",
    "cursor.executemany(insert_sql, rows)\n",
    "conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"âœ… most_used_venues table loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e0522f",
   "metadata": {},
   "source": [
    "# RANKING IMPROVEMENT AND GAME PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a88c1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open(\"sched.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "    season = json.load(f)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for week in season.get(\"weeks\", []):\n",
    "    week_number = week.get(\"sequence\")\n",
    "    for game in week.get(\"games\", []):\n",
    "        \n",
    "        season_id   = season.get(\"id\")\n",
    "        season_year = season.get(\"year\")\n",
    "        game_id     = game.get(\"id\")\n",
    "\n",
    "        home = game.get(\"home\", {})\n",
    "        away = game.get(\"away\", {})\n",
    "        scoring = game.get(\"scoring\", {})\n",
    "\n",
    "        home_points = scoring.get(\"home_points\")\n",
    "        away_points = scoring.get(\"away_points\")\n",
    "\n",
    "        # ---- Home team record\n",
    "        rows.append({\n",
    "            \"season_id\": season_id,\n",
    "            \"season_year\": season_year,\n",
    "            \"week\": week_number,\n",
    "            \"team_id\": home.get(\"id\"),\n",
    "            \"team_name\": home.get(\"name\"),\n",
    "            \"points_scored\": home_points,\n",
    "            \"game_id\": game_id\n",
    "        })\n",
    "\n",
    "        # ---- Away team record\n",
    "        rows.append({\n",
    "            \"season_id\": season_id,\n",
    "            \"season_year\": season_year,\n",
    "            \"week\": week_number,\n",
    "            \"team_id\": away.get(\"id\"),\n",
    "            \"team_name\": away.get(\"name\"),\n",
    "            \"points_scored\": away_points,\n",
    "            \"game_id\": game_id\n",
    "        })\n",
    "\n",
    "df_game_scores = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "acbfe6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” game_scores loaded!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import numpy as np\n",
    "\n",
    "df = df_game_scores.replace({np.nan: None})\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Alys@003!\",\n",
    "    database=\"ncaafb_db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "sql = \"\"\"\n",
    "INSERT INTO game_scores (\n",
    "    season_id,\n",
    "    season_year,\n",
    "    week,\n",
    "    team_id,\n",
    "    points_scored,\n",
    "    game_id\n",
    ") VALUES (%s,%s,%s,%s,%s,%s);\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(sql, df[[\n",
    "    \"season_id\",\"season_year\",\"week\",\n",
    "    \"team_id\",\"points_scored\",\"game_id\"\n",
    "]].values.tolist())\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"âœ” game_scores loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "abb559b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.5-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\paul\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (2.2.6)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\paul\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (1.16.2)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\paul\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (2.3.3)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\paul\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\paul\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\paul\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\paul\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\paul\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Downloading statsmodels-0.14.5-cp313-cp313-win_amd64.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 3.4/9.6 MB 18.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.9/9.6 MB 19.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 19.4 MB/s  0:00:00\n",
      "Downloading patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "\n",
      "   ---------------------------------------- 0/2 [patsy]\n",
      "   ---------------------------------------- 0/2 [patsy]\n",
      "   ---------------------------------------- 0/2 [patsy]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   -------------------- ------------------- 1/2 [statsmodels]\n",
      "   ---------------------------------------- 2/2 [statsmodels]\n",
      "\n",
      "Successfully installed patsy-1.0.2 statsmodels-0.14.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3149a61b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
